torch 2.1.0
transformers 4.35.2
accelerate 0.24.1
# of gpus:  1
Disentangle: True
loading llm model llama2-7b-chat-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:03<01:03, 63.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:30<00:00, 41.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:30<00:00, 45.06s/it]
use device  cuda:0
================================================================================
DQ then P007Q003 Two-Stage Pruning
Stage 1: d=4.0%, q=2.0%
Stage 2: p=7%, q=3%
================================================================================

================================================================================
DQ then P007Q003 Two-Stage Pruning
================================================================================
Stage 1: Prune top d=4.0% danger neurons NOT in top q=2.0% utility
Stage 2: Use PRE-EXISTING safety SNIP scores, then prune p=7.0%, q=3.0%

Storage paths:
  Stage 1 model: out/experiments/dq_then_p007q003/d_4_q_2/stage1_model
  Stage 2 safety scores: Using pre-existing align scores (read-only)
  Stage 2 model: out/experiments/dq_then_p007q003/d_4_q_2/stage2_model
================================================================================

prune every linear layer

[STAGE 1] Stage 1 model already exists at out/experiments/dq_then_p007q003/d_4_q_2/stage1_model
  Skipping Stage 1 pruning - will load saved model for Stage 2


[STAGE 2] Using PRE-EXISTING safety SNIP scores (skipping computation)
  Using base align scores from: out/llama2-7b-chat-hf/unstructured/wandg/align/wanda_score/

[STAGE 2] Stage 2 model already exists at out/experiments/dq_then_p007q003/d_4_q_2/stage2_model
  Skipping Stage 2 pruning - loading saved model instead

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:18<00:36, 18.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:29<00:14, 14.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:37<00:00, 11.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:37<00:00, 12.58s/it]

================================================================================
Two-stage pruning complete!
================================================================================

================================================================================
Evaluating Stage 1 Model
================================================================================
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.51s/it]
layer 0 sparsity 0.024369
layer 1 sparsity 0.026401
layer 2 sparsity 0.029004
layer 3 sparsity 0.029504
layer 4 sparsity 0.028900
layer 5 sparsity 0.028355
layer 6 sparsity 0.028327
layer 7 sparsity 0.028227
layer 8 sparsity 0.028345
layer 9 sparsity 0.027963
layer 10 sparsity 0.027945
layer 11 sparsity 0.028133
layer 12 sparsity 0.028922
layer 13 sparsity 0.028673
layer 14 sparsity 0.028865
layer 15 sparsity 0.029099
layer 16 sparsity 0.029289
layer 17 sparsity 0.029709
layer 18 sparsity 0.029535
layer 19 sparsity 0.029529
layer 20 sparsity 0.029969
layer 21 sparsity 0.030242
layer 22 sparsity 0.030698
layer 23 sparsity 0.031032
layer 24 sparsity 0.031120
layer 25 sparsity 0.030614
layer 26 sparsity 0.031275
layer 27 sparsity 0.029303
layer 28 sparsity 0.029820
layer 29 sparsity 0.029255
layer 30 sparsity 0.028819
layer 31 sparsity 0.026997
Stage 1 sparsity: 0.029007
calling set_model function
calling set_tokenizer function
Traceback (most recent call last):
  File "/workspace/projects/2881r-mini-project/main.py", line 1005, in <module>
    main()
  File "/workspace/projects/2881r-mini-project/main.py", line 360, in main
    results_stage1 = eval_zero_shot(
                     ^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/lib/eval.py", line 237, in eval_zero_shot
    results = evaluator.simple_evaluate(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/utils.py", line 243, in _wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/evaluator.py", line 114, in simple_evaluate
    task_dict = lm_eval.tasks.get_task_dict(tasks)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/tasks/__init__.py", line 404, in get_task_dict
    task_name_dict = {
                     ^
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/tasks/__init__.py", line 405, in <dictcomp>
    task_name: get_task(task_name)()
               ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/base.py", line 514, in __init__
    self.download(data_dir, cache_dir, download_mode)
  File "/workspace/projects/2881r-mini-project/lm-evaluation-harness/lm_eval/base.py", line 543, in download
    self.dataset = datasets.load_dataset(
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/datasets/load.py", line 2128, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/datasets/load.py", line 1814, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/datasets/load.py", line 1511, in dataset_module_factory
    raise e1 from None
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/datasets/load.py", line 1495, in dataset_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/datasets/load.py", line 1015, in get_module
    hfh_dataset_info = HfApi(config.HF_ENDPOINT).dataset_info(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/huggingface_hub/hf_api.py", line 1985, in dataset_info
    hf_raise_for_status(r)
  File "/workspace/projects/2881r-mini-project/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py", line 330, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 502 Server Error: Bad Gateway for url: https://huggingface.co/api/datasets/openbookqa
